{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Dataset as Weights and Biases Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonScript.modules.data_preprocessing import load_images_from_folder, ImageType, Label, ECGLabel, ecg_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = os.path.join(\".\", \"ecg_image_data\", \"test\")\n",
    "TRAIN_PATH = os.path.join(\".\", \"ecg_image_data\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_WITH_SIGN = os.path.join(\".\", \"data\", \"y\")\n",
    "# PATH_WITHOUT_SIGN = os.path.join(\".\", \"data\", \"n\")\n",
    "# IMAGE_SIZE = (250, 250)\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Images\n",
    "test_images = None\n",
    "test_labels = None\n",
    "for folder in os.listdir(TEST_PATH):\n",
    "    path = os.path.join(TEST_PATH, folder)\n",
    "    if not os.path.isdir(path):\n",
    "        print(path)\n",
    "        continue\n",
    "\n",
    "    images, label = load_images_from_folder(path, ecg_label_map[folder], IMAGE_SIZE, ImageType.ORIGINAL)\n",
    "    print(images.shape)\n",
    "    \n",
    "    if test_images is None:\n",
    "        test_images = images.copy()\n",
    "        test_labels = label.copy()\n",
    "    else:\n",
    "        test_images = np.concatenate((test_images, images), axis=0)\n",
    "        test_labels = np.concatenate((test_labels, label), axis=0)\n",
    "\n",
    "test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train Images\n",
    "train_images = None\n",
    "train_labels = None\n",
    "for folder in os.listdir(TRAIN_PATH):\n",
    "    path = os.path.join(TRAIN_PATH, folder)\n",
    "    if not os.path.isdir(path):\n",
    "        print(path)\n",
    "        continue\n",
    "\n",
    "    images, label = load_images_from_folder(path, ecg_label_map[folder], IMAGE_SIZE, ImageType.ORIGINAL)\n",
    "    print(images.shape)\n",
    "    \n",
    "    if train_images is None:\n",
    "        train_images = images.copy()\n",
    "        train_labels = label.copy()\n",
    "    else:\n",
    "        train_images = np.concatenate((train_images, images), axis=0)\n",
    "        train_labels = np.concatenate((train_labels, label), axis=0)\n",
    "\n",
    "train_images.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Validation set from train set\n",
    "train_images, validation_images, train_labels, validation_labels = (\n",
    "    train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0]), train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(validation_images[0]), validation_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_images[0]), test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.unique(train_labels)\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(categories))\n",
    "validation_labels = tf.keras.utils.to_categorical(validation_labels, num_classes=len(categories))\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape, validation_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"VisionTransformer\", job_type=\"load-data\", entity=\"@ass\") as run:\n",
    "    raw_data = wandb.Artifact(\n",
    "        \"ecg-image-data-no-preprocessing\", type=\"dataset\", metadata={\"source\": \"ecg-image-data\", \"size\": len(np.concatenate((train_images, validation_images, test_images), axis=0))}\n",
    "        )\n",
    "\n",
    "    # Training\n",
    "    with raw_data.new_file(\"training-no-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=train_images, labels=train_labels)\n",
    "\n",
    "    # Validation\n",
    "    with raw_data.new_file(\"validation-no-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=validation_images, labels=validation_labels)\n",
    "\n",
    "    # Test\n",
    "    with raw_data.new_file(\"test-no-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=test_images, labels=test_labels)\n",
    "\n",
    "    run.log_artifact(raw_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_sign_canny, labels_with_sign_canny = load_images_from_folder(\n",
    "    PATH_WITH_SIGN, Label.WITH_SIGN, IMAGE_SIZE, img_type=ImageType.CANNY\n",
    ")\n",
    "images_without_sign_canny, labels_without_sign_canny = load_images_from_folder(\n",
    "    PATH_WITHOUT_SIGN, Label.WITHOUT_SIGN, IMAGE_SIZE, img_type=ImageType.CANNY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_sign_morphology, labels_with_sign_morphology = load_images_from_folder(\n",
    "    PATH_WITH_SIGN, Label.WITH_SIGN, IMAGE_SIZE, img_type=ImageType.MORPHOLOGY\n",
    ")\n",
    "images_without_sign_morphology, labels_without_sign_morphology = (\n",
    "    load_images_from_folder(\n",
    "        PATH_WITHOUT_SIGN, Label.WITHOUT_SIGN, IMAGE_SIZE, img_type=ImageType.MORPHOLOGY\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_sign_normal, labels_with_sign_normal = load_images_from_folder(\n",
    "    PATH_WITH_SIGN, Label.WITH_SIGN, IMAGE_SIZE, img_type=ImageType.NORMAL\n",
    ")\n",
    "images_without_sign_normal, labels_without_sign_normal = load_images_from_folder(\n",
    "    PATH_WITHOUT_SIGN, Label.WITHOUT_SIGN, IMAGE_SIZE, img_type=ImageType.NORMAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_with_sign = np.concatenate(\n",
    "    (images_with_sign_canny, images_with_sign_morphology, images_with_sign_normal),\n",
    "    axis=-1,\n",
    ")\n",
    "images_without_sign = np.concatenate(\n",
    "    (\n",
    "        images_without_sign_canny,\n",
    "        images_without_sign_morphology,\n",
    "        images_without_sign_normal,\n",
    "    ),\n",
    "    axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_sign = np.array(labels_with_sign_canny)\n",
    "labels_without_sign = np.array(labels_without_sign_canny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = np.concatenate((images_with_sign, images_without_sign), axis=0)\n",
    "all_labels = np.concatenate((labels_with_sign, labels_without_sign), axis=0)\n",
    "all_images = all_images.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    all_images, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_images, validation_images, train_labels, validation_labels = (\n",
    "    train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with wandb.init(project=\"VisionTransformer\", job_type=\"load-data\") as run:\n",
    "    raw_data = wandb.Artifact(\n",
    "        \"swissimage-10cm-preprocessing\", type=\"dataset\", metadata={\"source\": \"Swissimage 10cm\", \"size\": len(all_images)}\n",
    "        )\n",
    "\n",
    "    # Training\n",
    "    with raw_data.new_file(\"training-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=train_images, labels=train_labels)\n",
    "\n",
    "    # Validation\n",
    "    with raw_data.new_file(\"validation-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=validation_images, labels=validation_labels)\n",
    "\n",
    "    # Test\n",
    "    with raw_data.new_file(\"test-preprocessing.npy\", mode=\"wb\") as fh:\n",
    "        np.savez_compressed(fh, images=test_images, labels=test_labels)\n",
    "\n",
    "    run.log_artifact(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"VisionTransformer\", entity=\"@ass\") as run:\n",
    "    run.name = \"deleteme\"\n",
    "    artifact = run.use_artifact('@ass/VisionTransformer/ecg-image-data-no-preprocessing:v0', type='dataset')\n",
    "    artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load(\"artifacts/ecg-image-data-no-preprocessing:v0/test-no-preprocessing.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(loaded[\"images\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythonScript.modules.data_preprocessing import apply_canny, apply_morphology, black_and_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ArtifactDataset(Dataset):\n",
    "    def __init__(self, artifact_uri: str, artifact_name: str, run, transform=None):\n",
    "        self.artifact_uri = artifact_uri\n",
    "        self.transform = transform\n",
    "\n",
    "        # Download Artifact from Wandb\n",
    "        artifact = run.use_artifact(artifact_uri, type=\"dataset\")\n",
    "        artifact_dir = artifact.download()\n",
    "        artifact_data = np.load(os.path.join(artifact_dir, artifact_name))\n",
    "\n",
    "        self.images = artifact_data[\"images\"]\n",
    "        self.labels = artifact_data[\"labels\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "\n",
    "        combined_image = Image.fromarray(np.uint8(image * 255))\n",
    "\n",
    "        if self.transform:\n",
    "            combined_image = self.transform(combined_image)\n",
    "\n",
    "        return combined_image, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerkehrsschilderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for label, subfolder in enumerate([\"y\", \"n\"]):\n",
    "            folder_path = os.path.join(self.root_dir, subfolder)\n",
    "            for image_name in os.listdir(folder_path):\n",
    "                self.images.append(os.path.join(folder_path, image_name))\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        canny_image = apply_canny(image, (224, 224))\n",
    "        morphology_image = apply_morphology(image, (224, 224))\n",
    "        bw_image = black_and_white(image, (224, 224))\n",
    "\n",
    "        combined_image = np.concatenate(\n",
    "            (canny_image, morphology_image, bw_image), axis=-1\n",
    "        )\n",
    "        combined_image = Image.fromarray(np.uint8(combined_image))\n",
    "        if self.transform:\n",
    "            combined_image = self.transform(combined_image)\n",
    "\n",
    "        return combined_image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = VerkehrsschilderDataset(\"data\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"VisionTransformer\") as run:\n",
    "    run.name = \"deleteme\"\n",
    "    training_dataset = ArtifactDataset(\n",
    "        \"silvan-wiedmer-fhgr/VisionTransformer/swissimage-10cm-preprocessing:v1\",\n",
    "        \"training-preprocessing.npy\",\n",
    "        run,\n",
    "        transform,\n",
    "    )\n",
    "\n",
    "    training_loader = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    for images, labels in training_loader:\n",
    "        plt.imshow(images[5].permute(1,2,0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded[\"images\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded[\"images\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded[\"images\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.resize(loaded[\"images\"][0], (224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.resize(loaded[\"images\"][0], IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(loaded[\"images\"][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
